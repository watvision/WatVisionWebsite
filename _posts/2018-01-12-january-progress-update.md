---
layout: post
title:  "January Progress Update"
author: Craig Loewen
thumbnailpath: /img/january-progress-update/overalluse.JPG
---

It's been 4 months since our team has started this project, and we are ready to show off some major updates!

##### Device Summary

The goal of our project is to create a way for a visually impaired person to use any touch screen. To this end, we have designed a small wearable, which is in the shape of a ring that fits on your finger. We have also designed an app for your phone, that when pointed at a screen will be able to understand all of the interactable screen elements that are present (such as buttons). By pointing your phone towards the screen and moving over the elements with the wearable, the app is able to determine what you are pointing at, and read the information of the element out to you: such as the text of the button. By moving the wearable over the screen you'll be able to fully understand the screen's information and be able to press whatever option you like.

##### How you're going to use our device

<div class="row">
    <div class="col-sm-6">

        <img src="/img/january-progress-update/overalluse.JPG" alt="User holding their phone in their right hand and using the Watvision wearable in their left hand to explore the screen" class="img-responsive" />
        <p>The setup for the use of the app is demonstrated using the Camera App</p>

    </div>

    <div class="col-sm-6">
            <li>Open the app and point the camera at the screen</li>
            <li>The application will notify the user when it fully detects the menu</li>
            <li>Use the wearable to explore screen elements and have them read out to you</li>
            <li>Press on the touchscreen when the wearable is over a desired element</li>
    </div>
</div>
<br/>



##### What our device will do for you

<div class="row">
    <div class="col-md-6">
        Provide the means to use any touch screen by:
        <li>Reading out text on a touch screen when the device is hovering over it</li>
        <li>Indicating the type of interactable element that is present on the screen: i.e: button, tab, checkbox, etc.</li>
        <li>Providing the ability to understand any touch screen without needing the original touchscreen manufacturer to modify their screens</li>
        <li>Empowering users to use touch screens independently</li>
    </div>

    <div class="col-md-6">
        <img src="/img/january-progress-update/screensexample.JPG" alt="Touch screens showing which highlighted information is going to be shown through the app" class="img-responsive" />
    </div>

    
</div>
<br/>

##### Moving Forwards

We aim to have a preliminary demo for the project ready by next week, and will be posting its details to the blog. We plan to judge our prototype based upon these five criteria:

* Cost - Measured in USD
* Usability - Measured by the weight of the wearable in Kilograms
* Accuracy - Measured in percentage of accurately defined elements
* Speed - Measured in how quickly a user can complete a workflow of a touch screen in seconds
* Reliability - Measured in the hours of battery life

Additionally, there has been a lot of behind the scenes engineering. The team has been working hard to sort out the details of how to tackle the complicated problem ahead of us, and have decided upon the design for the project. Currently, we are developing the aforementioned prototype with the aim of using this to gather some user feedback. From there, we can iterate on our design to have a polished product for demo day. 

We look forwards to posting more information about our work soon! Stay tuned! 